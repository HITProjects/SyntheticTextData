{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab20cd6-6531-4624-b171-29d4f1ff4cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\guyy6\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2592e409-0aaf-4171-99f1-73bc0621aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import requests\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a077fb20-63b0-4988-be8a-152c1aec2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMClient:\n",
    "    def __init__(self, provider=\"openai\", api_key=None, base_url=None, model=\"gpt-4o-mini\"):\n",
    "        self.provider = provider\n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        self.base_url = base_url\n",
    "\n",
    "        if provider == \"openai\":\n",
    "            self.client = OpenAI(api_key=self.api_key)\n",
    "\n",
    "        elif provider == \"ollama\":\n",
    "            if not self.base_url:\n",
    "                self.base_url = \"http://localhost:11434\"\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unknown provider. Use 'openai' or 'ollama'.\")\n",
    "\n",
    "    def generate(self, prompt):\n",
    "        \"\"\"Unified text generation interface (no streaming for Ollama).\"\"\"\n",
    "\n",
    "        # ---------- OpenAI ----------\n",
    "        if self.provider == \"openai\":\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "\n",
    "        # ---------- Ollama ----------\n",
    "        elif self.provider == \"ollama\":\n",
    "            url = f\"{self.base_url}/api/generate\"\n",
    "\n",
    "            response = requests.post(\n",
    "                url,\n",
    "                json={\n",
    "                    \"model\": self.model,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"stream\": False       # <<< this fixes ALL freeze issues\n",
    "                }\n",
    "            )\n",
    "\n",
    "            data = response.json()       # now safe: single JSON object\n",
    "            return data[\"response\"].strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a04662f-0a59-4f5d-9dbe-a86d01598191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "\n",
    "class RobustDataGenerator:\n",
    "    # --- 1. Constants and Configuration ---\n",
    "\n",
    "    ASPECTS = [\n",
    "        \"difficulty\", \"clarity\", \"workload\", \"lecturer_quality\",\n",
    "        \"exam_fairness\", \"relevance\", \"interest\", \"support\",\n",
    "        \"materials\", \"overall_experience\"\n",
    "    ]\n",
    "\n",
    "    ASPECT_KEYWORDS = {\n",
    "        \"difficulty\": [\"hard\", \"easy\", \"challenging\", \"struggle\", \"breeze\", \"complex\", \"simple\", \"tough\", \"demanding\", \"intense\", \"impossible\", \"walk in the park\", \"piece of cake\", \"advanced\", \"basic\", \"tricky\", \"concept\", \"abstract\", \"theory\", \"sweat\", \"nightmare\"],\n",
    "        \"clarity\": [\"explain\", \"understand\", \"confusing\", \"clear\", \"fuzzy\", \"articulate\", \"messy\", \"organized\", \"structured\", \"all over the place\", \"coherent\", \"follow\", \"lost\", \"crystal clear\", \"vague\", \"ambiguous\", \"examples\", \"click\", \"make sense\"],\n",
    "        \"workload\": [\"assignments\", \"homework\", \"time\", \"hours\", \"busy\", \"heavy\", \"light\", \"projects\", \"deadlines\", \"overwhelmed\", \"drowning\", \"manageable\", \"weekend\", \"free time\", \"load\", \"tasks\", \"submission\", \"pressure\", \"burnout\", \"life\"],\n",
    "        \"lecturer_quality\": [\"professor\", \"lecturer\", \"teach\", \"speaker\", \"explained\", \"engaging\", \"boring\", \"monotone\", \"charismatic\", \"passion\", \"enthusiastic\", \"cares\", \"knowledgeable\", \"expert\", \"delivery\", \"teaching style\", \"mentor\", \"vibes\"],\n",
    "        \"exam_fairness\": [\"exam\", \"test\", \"grading\", \"grade\", \"score\", \"midterm\", \"final\", \"fair\", \"unfair\", \"curve\", \"questions\", \"representative\", \"surprise\", \"trick questions\", \"time limit\", \"prepared\", \"study\", \"pass\", \"fail\", \"cheat sheet\"],\n",
    "        \"relevance\": [\"job\", \"industry\", \"real-world\", \"theoretical\", \"practical\", \"career\", \"useful\", \"useless\", \"applicable\", \"market\", \"outdated\", \"modern\", \"interview\", \"future\", \"hiring\", \"skills\", \"application\", \"cv\"],\n",
    "        \"interest\": [\"boring\", \"fascinating\", \"sleep\", \"engaging\", \"curious\", \"fun\", \"snooze\", \"excited\", \"dry\", \"monotonous\", \"captivating\", \"eye-opening\", \"interesting\", \"dull\", \"waste of time\", \"love\", \"hate\", \"passion\", \"meh\"],\n",
    "        \"support\": [\"help\", \"email\", \"office hours\", \"answer\", \"ignore\", \"available\", \"TA\", \"teaching assistant\", \"reply\", \"ghosted\", \"responsive\", \"feedback\", \"accessible\", \"reach out\", \"supportive\", \"on your own\", \"piazza\"],\n",
    "        \"materials\": [\"slides\", \"book\", \"moodle\", \"recording\", \"textbook\", \"notes\", \"presentation\", \"resources\", \"video\", \"upload\", \"link\", \"PDF\", \"reading\", \"content\", \"access\", \"quality\", \"organized\", \"repository\", \"github\"],\n",
    "        \"overall_experience\": [\"overall\", \"course\", \"semester\", \"experience\", \"recommend\", \"regret\", \"worth it\", \"avoid\", \"must-take\", \"rating\", \"glad\", \"general\", \"impression\", \"atmosphere\", \"vibe\", \"conclusion\", \"waste\", \"gem\"]\n",
    "    }\n",
    "\n",
    "    SENTIMENTS = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "    FORBIDDEN_PHRASES = [\n",
    "        \"underwhelming\", \"overwhelmingly\", \"insightful\", \"invaluable\", \"facilitated\",\n",
    "        \"comprehensive foundation\", \"challenging yet rewarding\", \"well-deserved\",\n",
    "        \"exceeded expectations\", \"surpassed expectations\", \"notable\", \"commendable\",\n",
    "        \"lackluster\", \"optimal\", \"pivotal\", \"foster\", \"enhancing\", \"utilize\",\n",
    "        \"on the complexity front\", \"a mixed bag\", \"a testament to\",\n",
    "        \"wrap my head around\", \"reading from a script\", \"monotonous voice\",\n",
    "        \"left me struggling\", \"ignite a genuine sense\", \"solid 5/10\", \"mixed experience\"\n",
    "    ]\n",
    "\n",
    "    STYLES = [\n",
    "        \"Casual (Texting style: lowercase, no punctuation, slang like 'tbh', 'idk', 'tho', fragments)\",\n",
    "        \"Simple & Direct (Use only common words. No academic jargon. Like talking to a friend)\",\n",
    "        \"Rant/Rave (Emotional, very subjective, lots of punctuation !!! or ...)\",\n",
    "        \"Short (Max 10-15 words. Fragments allowed)\",\n",
    "        \"Analytic but Simple (Explains 'why' but uses simple language)\",\n",
    "        \"Confused Student (Unsure about things, asks rhetorical questions)\",\n",
    "    ]\n",
    "\n",
    "    COURSES = [\n",
    "        {\"name\": \"Linear Algebra\", \"desc\": \"Matrices, vectors, eigenvalues.\"},\n",
    "        {\"name\": \"Introduction to Programming\", \"desc\": \"Python, algorithms, basic coding.\"},\n",
    "        {\"name\": \"Data Structures\", \"desc\": \"Trees, graphs, hash tables, complexity.\"},\n",
    "        {\"name\": \"Operating Systems\", \"desc\": \"Processes, threads, memory management.\"},\n",
    "        {\"name\": \"Machine Learning\", \"desc\": \"Neural networks, models, clustering.\"},\n",
    "        {\"name\": \"Computer Networks\", \"desc\": \"TCP/IP, routing, protocols.\"},\n",
    "        {\"name\": \"Databases\", \"desc\": \"SQL, normalization, indexing.\"},\n",
    "        {\"name\": \"Calculus 2\", \"desc\": \"Integrals, series, convergence tests.\"},\n",
    "        {\"name\": \"Probability & Statistics\", \"desc\": \"Distributions, hypothesis testing.\"},\n",
    "        {\"name\": \"Digital Systems\", \"desc\": \"Logic gates, boolean algebra, hardware design.\"},\n",
    "        {\"name\": \"Physics 1: Mechanics\", \"desc\": \"Newton's laws, energy, momentum.\"},\n",
    "        {\"name\": \"Algorithms 1\", \"desc\": \"Sorting, searching, dynamic programming.\"},\n",
    "        {\"name\": \"Web Development\", \"desc\": \"HTML, CSS, JavaScript, React.\"},\n",
    "        {\"name\": \"Cyber Security Basics\", \"desc\": \"Encryption, attacks, network defense.\"}\n",
    "    ]\n",
    "\n",
    "    LECTURERS = [\n",
    "        {\"name\": \"Dr. Cohen\", \"gender\": \"Male\"},\n",
    "        {\"name\": \"Prof. Levi\", \"gender\": \"Female\"},\n",
    "        {\"name\": \"Dr. Mizrahi\", \"gender\": \"Male\"},\n",
    "        {\"name\": \"Dr. Kaplan\", \"gender\": \"Female\"},\n",
    "        {\"name\": \"Prof. Baruch\", \"gender\": \"Male\"},\n",
    "        {\"name\": \"Dr. Shapira\", \"gender\": \"Female\"},\n",
    "        {\"name\": \"Dr. Adler\", \"gender\": \"Male\"},\n",
    "        {\"name\": \"Prof. Klein\", \"gender\": \"Male\"}\n",
    "    ]\n",
    "\n",
    "    PREFIXES = [\n",
    "        \"Overall, \", \"To be honest, \", \"Frankly, \", \"In my opinion, \", \"Actually, \",\n",
    "        \"Truth be told, \", \"Looking back, \", \"All in all, \", \"Basically, \",\n",
    "        \"So, \", \"Okay, so \", \"Tbh, \", \"Ngl, \", \"Look, \", \"Just saying, \",\n",
    "        \"Man, \", \"Dude, \", \"Seriously, \", \"Omg, \", \"Wow, \",\n",
    "        \"Bottom line: \", \"Short version: \", \"Straight up: \", \"Real talk: \",\n",
    "        \"Just finished this course and \", \"Don't take this if \", \"Take this if \",\n",
    "        \"After finishing the semester, \", \"I really thought \", \"I expected \",\n",
    "        \"Coming into this course, \", \"If I could choose again, \"\n",
    "    ]\n",
    "\n",
    "    STUDENT_YEARS = [\n",
    "        \"Freshman (1st year)\", \"Sophomore (2nd year)\", \"Junior (3rd year)\", \"Senior (4th year)\"\n",
    "    ]\n",
    "    COURSE_STATES = [\n",
    "        \"Currently taking\", \"Completed recently\", \"Took it a while ago\", \"Retaking the course\"\n",
    "    ]\n",
    "    GRADES = [\n",
    "        \"A (Excellent)\", \"B (Good)\", \"C (Average)\", \"D (Barely passed)\", \"F (Failed)\"\n",
    "    ]\n",
    "\n",
    "    def __init__(self, llm_client: \"LLMClient\", refiner_llm: \"LLMClient\" = None):\n",
    "        self.llm = llm_client\n",
    "        self.refiner_llm = refiner_llm or llm_client\n",
    "\n",
    "    # ---------- Helpers ----------\n",
    "\n",
    "    def get_random_course_and_lecturer(self):\n",
    "        course = random.choice(self.COURSES)\n",
    "        lecturer = random.choice(self.LECTURERS)\n",
    "        return course[\"name\"], course[\"desc\"], lecturer\n",
    "\n",
    "    # ---------- Text Post-processing (The Cleaner) ----------\n",
    "\n",
    "    def _postprocess_review(self, text: str) -> str:\n",
    "        if not text:\n",
    "            return \"\"\n",
    "\n",
    "        s = text.strip()\n",
    "\n",
    "        # 1. ×—×™×œ×•×¥ ×—×›× ××ª×•×š ××¨×›××•×ª\n",
    "        quotes_match = re.search(r'[\"\\'](.*?)[\"\\']', s, re.DOTALL)\n",
    "        if quotes_match:\n",
    "            content = quotes_match.group(1).strip()\n",
    "            if len(content) > 3: # ×”×’× ×” ××¤× ×™ ×ª×•×›×Ÿ ×§×¦×¨ ××“×™\n",
    "                s = content\n",
    "\n",
    "        # 2. × ×™×§×•×™ ×”×§×“××•×ª (Prefixes)\n",
    "        lines = s.split(\"\\n\")\n",
    "        clean_lines = []\n",
    "        for line in lines:\n",
    "            if not re.match(r'^(Here|Sure|Okay|Review|Rewrite|Style|The review)', line.strip(), re.IGNORECASE):\n",
    "                clean_lines.append(line)\n",
    "        s = \" \".join(clean_lines).strip()\n",
    "\n",
    "        if \":\" in s[:40]:\n",
    "             s = s.split(\":\", 1)[1].strip()\n",
    "\n",
    "        # 3. × ×™×§×•×™ ×¡×™×•××•×ª ×•×”×¢×¨×•×ª\n",
    "        s = re.sub(r'\\(Note:.*?\\)$', '', s, flags=re.IGNORECASE | re.DOTALL).strip()\n",
    "        s = re.sub(r'\\((i kept|maintained|style|sentiment|wrote|just).*?\\)$', '', s, flags=re.IGNORECASE | re.DOTALL).strip()\n",
    "\n",
    "        closers = [\"Let me know\", \"Hope this\", \"Is there anything\", \"Feel free\", \"Does this meet\"]\n",
    "        for closer in closers:\n",
    "            if closer.lower() in s.lower():\n",
    "                s = re.split(closer, s, flags=re.IGNORECASE)[0].strip()\n",
    "\n",
    "        # --- 4. × ×™×§×•×™ ×–× ×‘×•×ª ××’×¨×¡×™×‘×™ (×”×ª×™×§×•×Ÿ ×”×’×“×•×œ) ---\n",
    "        # ×¨×©×™××” ×©×œ ××™×œ×™× ×©××¡×•×¨ ×©×™×¡×™×™××• ××©×¤×˜\n",
    "        bad_endings = [\n",
    "            \"and\", \"but\", \"so\", \"or\", \"because\", \"cuz\", \"tho\", \"although\", \"if\", \"that\", # ××™×œ×•×ª ×§×™×©×•×¨\n",
    "            \"they\", \"he\", \"she\", \"it\", \"we\", \"i\", \"you\", # ×’×•×¤×™×\n",
    "            \"the\", \"a\", \"an\", \"my\", \"ur\", \"his\", \"her\", \"their\", # ××™×œ×•×ª ×™×—×¡\n",
    "            \"was\", \"is\", \"are\", \"were\", \"been\", \"be\", # ×¤×•×¢×œ×™ ×¢×–×¨\n",
    "            \"didn\", \"wasn\", \"weren\", \"isn\", \"aren\", \"can\", \"cant\", \"wont\", \"dont\", # ××™×œ×™× ×—×ª×•×›×•×ª × ×¤×•×¦×•×ª\n",
    "            \"feelin\", \"hopin\", \"tryin\", \"goin\", # ×’×¨×•× ×“×™×•× ×—×ª×•×š\n",
    "            \"of\", \"in\", \"on\", \"at\", \"to\", \"for\", \"with\", \"about\" # ××™×œ×•×ª ×™×—×¡\n",
    "        ]\n",
    "        \n",
    "        # ×œ×•×œ××” ×©××•×¨×™×“×” ××™×œ×™× ××—×¨×•× ×•×ª ×›×œ ×¢×•×“ ×”×Ÿ ×‘×¨×©×™××” ×”×‘×¢×™×™×ª×™×ª\n",
    "        # (×›×™ ×œ×¤×¢××™× ×™×© ×¨×¦×£: \"and that the...\")\n",
    "        words = s.split()\n",
    "        while words and (words[-1].lower() in bad_endings or len(words[-1]) < 2): # ××•×—×§ ×’× ××•×ª×™×•×ª ×‘×•×“×“×•×ª ×‘×¡×•×£ (×—×•×¥ ×-a/i ×©××˜×•×¤×œ×•×ª ×‘×¨×©×™××”)\n",
    "            words.pop()\n",
    "        \n",
    "        s = \" \".join(words)\n",
    "\n",
    "        # 5. ×ª×™×§×•×Ÿ ×”×ª×—×œ×•×ª ×—×ª×•×›×•×ª\n",
    "        s = re.sub(r\"^'?m\\s\", \"I'm \", s).strip()\n",
    "        s = re.sub(r\"^'?s\\s\", \"It's \", s).strip()\n",
    "        s = re.sub(r\"^'?re\\s\", \"They're \", s).strip()\n",
    "        s = re.sub(r\"^'?t\\s\", \"Didn't \", s).strip()\n",
    "        \n",
    "        # ×”×©×œ××ª n't ×œ××™×œ×™× ×©×‘×•×¨×•×ª ×‘×”×ª×—×œ×” (×›××• \"t know\")\n",
    "        if s.startswith(\"t \") or s.startswith(\"d \"):\n",
    "             s = \"Didn't \" + s[2:]\n",
    "\n",
    "        # 6. × ×™×§×•×™ ×¡×•×¤×™\n",
    "        s = s.strip('\"\\' ,.-') # ××•×¨×™×“ ×’× × ×§×•×“×•×ª ×•×¤×¡×™×§×™× ××™×•×ª×¨×™× ××”×§×¦×•×•×ª\n",
    "        s = \" \".join(s.split())\n",
    "        s = re.sub(r'\\b(Dr|Prof)\\.?$', '', s).strip()\n",
    "\n",
    "        return s\n",
    "\n",
    "    def _mess_up_text(self, text: str, style: str) -> str:\n",
    "        # ×¤×•× ×§×¦×™×” ×©××•×¡×™×¤×” ××•×¤×™ ×× ×•×©×™ ×œ×¡×’× ×•× ×•×ª ×œ× ×¨×©××™×™×\n",
    "        if \"Casual\" not in style and \"Rant\" not in style and \"Short\" not in style:\n",
    "            return text\n",
    "\n",
    "        if random.random() > 0.3:\n",
    "            text = text.lower()\n",
    "        if text.endswith(\".\"):\n",
    "            text = text[:-1]\n",
    "\n",
    "        replacements = {\n",
    "            \"to\": \"2\", \"for\": \"4\", \"you\": \"u\", \"are\": \"r\", \"because\": \"cuz\",\n",
    "            \"really\": \"rly\", \"please\": \"plz\", \"people\": \"ppl\", \"homework\": \"hw\",\n",
    "            \"though\": \"tho\", \"through\": \"thru\", \"and\": \"&\", \"professor\": \"prof\",\n",
    "        }\n",
    "\n",
    "        words = text.split()\n",
    "        new_words = []\n",
    "        for w in words:\n",
    "            clean_w = re.sub(r\"[^\\w\\s]\", \"\", w).lower()\n",
    "            if clean_w in replacements and random.random() > 0.4:\n",
    "                new_words.append(replacements[clean_w])\n",
    "            else:\n",
    "                new_words.append(w)\n",
    "\n",
    "        return \" \".join(new_words)\n",
    "\n",
    "    def _add_noise(self, text: str) -> str:\n",
    "        if not text or len(text) < 15:\n",
    "            return text\n",
    "        if random.random() > 0.4:\n",
    "            return text\n",
    "\n",
    "        s = text\n",
    "        op = random.choice([\"drop_char\", \"remove_space\"])\n",
    "\n",
    "        if op == \"drop_char\" and len(s) > 5:\n",
    "            # ××ª×—×™×œ×™× ×-1 ×›×“×™ ×œ× ×œ××—×•×§ ××ª ×”××•×ª ×”×¨××©×•× ×” ×‘×˜×¢×•×ª\n",
    "            i = random.randint(1, len(s) - 1)\n",
    "            if s[i].isalpha():\n",
    "                s = s[:i] + s[i + 1 :]\n",
    "        elif op == \"remove_space\":\n",
    "            match = re.search(r\"[.,!?]\\s+\", s)\n",
    "            if match:\n",
    "                start, end = match.span()\n",
    "                s = s[: start + 1] + s[end:]\n",
    "\n",
    "        return s\n",
    "\n",
    "    def _ensure_not_starting_with_i(self, text: str) -> str:\n",
    "        if not text:\n",
    "            return text\n",
    "        s = text.lstrip()\n",
    "        # ××•×¡×™×¤×™× ×¤×ª×™×— ×¨×§ ×× ×”×˜×§×¡×˜ ××¨×•×š ××¡×¤×™×§ ×•××ª×—×™×œ ×‘-I\n",
    "        if len(s.split()) > 7 and re.match(r\"^i\\b\", s, flags=re.IGNORECASE):\n",
    "            prefix = random.choice(self.PREFIXES)\n",
    "            s = prefix + s\n",
    "        return s\n",
    "\n",
    "    def _enforce_style_length(self, text: str, style: str) -> str:\n",
    "        \"\"\"Force length constraints to avoid run-on sentences in short styles.\"\"\"\n",
    "        words = text.split()\n",
    "        if not words:\n",
    "            return text\n",
    "\n",
    "        if \"Minimalist\" in style:\n",
    "            max_w = 6\n",
    "            if len(words) > max_w:\n",
    "                words = words[:max_w]\n",
    "            return \" \".join(words)\n",
    "\n",
    "        if \"Short\" in style:\n",
    "            max_w = 15\n",
    "            if len(words) > max_w:\n",
    "                words = words[:max_w]\n",
    "            return \" \".join(words)\n",
    "\n",
    "        if len(words) > 60:\n",
    "            words = words[:60]\n",
    "        return \" \".join(words)\n",
    "\n",
    "    # ---------- 3. Prompts ----------\n",
    "\n",
    "    def _build_gen_prompt(\n",
    "        self,\n",
    "        course_name: str,\n",
    "        course_desc: str,\n",
    "        lecturer_name: str,\n",
    "        lecturer_gender: str,\n",
    "        aspect_labels: dict,\n",
    "        style: str,\n",
    "        student_year: str,\n",
    "        course_state: str,\n",
    "        grade: str,\n",
    "    ) -> str:\n",
    "        aspect_instructions = []\n",
    "        for aspect, sentiment in aspect_labels.items():\n",
    "            keywords = \", \".join(self.ASPECT_KEYWORDS.get(aspect, []))\n",
    "            instruction = f\"- For '{aspect}' ({sentiment}): Use keywords like: {keywords}.\"\n",
    "\n",
    "            if aspect == \"clarity\" and sentiment == \"positive\":\n",
    "                instruction += \" (CONSTRAINT: Do NOT use words like 'puzzle' or 'confusing').\"\n",
    "\n",
    "            if sentiment == \"neutral\":\n",
    "                instruction += \" (CONSTRAINT: Do NOT be enthusiastic. Use 'okay', 'fine', 'average', 'standard').\"\n",
    "\n",
    "            aspect_instructions.append(instruction)\n",
    "\n",
    "        aspect_guidance_str = \"\\n\".join(aspect_instructions)\n",
    "        forbidden_str = \", \".join(self.FORBIDDEN_PHRASES)\n",
    "\n",
    "        length_constraint = \"Maximum 30 words.\"\n",
    "        if \"Minimalist\" in style:\n",
    "            length_constraint = \"MAXIMUM 5-7 WORDS. No full sentences.\"\n",
    "        elif \"Short\" in style:\n",
    "            length_constraint = \"Maximum 15 words. Fragments allowed.\"\n",
    "        elif \"Casual\" in style or \"Rant\" in style:\n",
    "            length_constraint = \"Maximum 25 words.\"\n",
    "\n",
    "        grade_instruction = \"\"\n",
    "        if \"D\" in grade or \"F\" in grade:\n",
    "            grade_instruction = \"The grade is low. You can sound disappointed about the grade, BUT you must still respect the specific Aspect Sentiments.\"\n",
    "\n",
    "        return f\"\"\"\n",
    "Write a student review about a university course.\n",
    "\n",
    "STYLE: {style}\n",
    "LENGTH: {length_constraint}\n",
    "\n",
    "FORBIDDEN WORDS (Do NOT use these):\n",
    "{forbidden_str}\n",
    "\n",
    "RULES:\n",
    "- Sound like a REAL STUDENT. Imperfect grammar is okay.\n",
    "- Do NOT start with \"I\" unless necessary.\n",
    "- Do NOT add meta-comments.\n",
    "- Minimalist style MUST be tiny.\n",
    "\n",
    "ASPECTS TO COVER:\n",
    "{json.dumps(aspect_labels, indent=2)}\n",
    "\n",
    "DETAILS:\n",
    "{aspect_guidance_str}\n",
    "\n",
    "CONTEXT:\n",
    "- Course: {course_name} ({course_desc})\n",
    "- Lecturer: {lecturer_name} ({lecturer_gender})\n",
    "- Student: {student_year}, {course_state}, Grade: {grade}\n",
    "{grade_instruction}\n",
    "\n",
    "Output ONLY the review text.\n",
    "\"\"\"\n",
    "\n",
    "    def _build_refiner_prompt(self, original_review: str, aspect_labels: dict, style: str) -> str:\n",
    "        return f\"\"\"\n",
    "You are a student. Rewrite this review to match the style: \"{style}\".\n",
    "Original: \"{original_review}\"\n",
    "\n",
    "IMPORTANT: Output ONLY the review text. NO preamble.\n",
    "\n",
    "Constraints:\n",
    "- Keep the sentiment: {json.dumps(aspect_labels)}\n",
    "- If Casual: use lowercase, slang (tbh, rn), no periods.\n",
    "- If Minimalist: Keep it under 6 words.\n",
    "- Don't use big words.\n",
    "\"\"\"\n",
    "\n",
    "    # ---------- 4. Main API ----------\n",
    "\n",
    "    def generate_single(self):\n",
    "        # 1. ×‘×•×—×¨×™× ×§×•×¨×¡ ×•××¨×¦×”\n",
    "        course_name, course_desc, lecturer_obj = self.get_random_course_and_lecturer()\n",
    "\n",
    "        style = random.choice(self.STYLES)\n",
    "        student_year = random.choice(self.STUDENT_YEARS)\n",
    "        course_state = random.choice(self.COURSE_STATES)\n",
    "\n",
    "        # 2. ×œ×•×’×™×§×”: Retaking ×’×•×¨×¨ ×¦×™×•×Ÿ × ××•×š\n",
    "        if course_state == \"Retaking the course\":\n",
    "            grade = random.choice([\"F (Failed)\", \"D (Barely passed)\"])\n",
    "        else:\n",
    "            grade = random.choice(self.GRADES)\n",
    "\n",
    "        # 3. ×œ×•×’×™×§×”: × ×›×©×œ ×œ× ×™×›×•×œ ×œ×”×™×•×ª \"×”×•×©×œ× ×‘×”×¦×œ×—×”\"\n",
    "        if \"F\" in grade and \"Completed\" in course_state:\n",
    "            course_state = \"Failed recently\"\n",
    "\n",
    "        # 4. ×“×’×™××ª ××¡×¤×§×˜×™× ×•×”×ª×××” ×œ×•×’×™×ª ×œ×¦×™×•×Ÿ\n",
    "        num_aspects = random.randint(1, 3)\n",
    "        selected_aspects_list = random.sample(self.ASPECTS, num_aspects)\n",
    "        aspect_labels = {}\n",
    "\n",
    "        for a in selected_aspects_list:\n",
    "            # ×× × ×›×©×œ×™×, ×—×•×•×™×” ×›×œ×œ×™×ª/×§×•×©×™ ×œ× ×™×›×•×œ×™× ×œ×”×™×•×ª ×—×™×•×‘×™×™×\n",
    "            if (\"F\" in grade or \"D\" in grade) and a in [\"overall_experience\", \"difficulty\", \"exam_fairness\"]:\n",
    "                aspect_labels[a] = random.choice([\"negative\", \"neutral\"])\n",
    "            # ×× ××¦×˜×™×™× ×™×, ×—×•×•×™×” ×›×œ×œ×™×ª ×‘×“\"×› ×œ× ×©×œ×™×œ×™×ª (××œ× ×× ×¨×•×¦×™× ×¦×™× ×™×•×ª)\n",
    "            elif \"A\" in grade and a == \"overall_experience\":\n",
    "                aspect_labels[a] = random.choice([\"positive\", \"neutral\"])\n",
    "            else:\n",
    "                aspect_labels[a] = random.choice(self.SENTIMENTS)\n",
    "\n",
    "        # 5. ×™×¦×™×¨×” ×¨××©×•× ×™×ª\n",
    "        gen_prompt = self._build_gen_prompt(\n",
    "            course_name,\n",
    "            course_desc,\n",
    "            lecturer_obj[\"name\"],\n",
    "            lecturer_obj[\"gender\"],\n",
    "            aspect_labels,\n",
    "            style,\n",
    "            student_year,\n",
    "            course_state,\n",
    "            grade,\n",
    "        )\n",
    "        gen_raw = self.llm.generate(gen_prompt)\n",
    "        gen_text = self._postprocess_review(gen_raw)\n",
    "\n",
    "        # 6. ×¢×™×“×•×Ÿ (Refinement)\n",
    "        refiner_prompt = self._build_refiner_prompt(gen_text, aspect_labels, style)\n",
    "        ref_raw = self.refiner_llm.generate(refiner_prompt)\n",
    "        ref_text = self._postprocess_review(ref_raw)\n",
    "\n",
    "        # 7. ×’×™××•×¨×™× (×œ×›×œ×•×š, ×¨×¢×©, ××›×™×¤×ª ××•×¨×š)\n",
    "        ref_text = self._mess_up_text(ref_text, style)\n",
    "        ref_text = self._ensure_not_starting_with_i(ref_text)\n",
    "        ref_text = self._add_noise(ref_text)\n",
    "        ref_text = self._enforce_style_length(ref_text, style)\n",
    "\n",
    "        return {\n",
    "            \"course_name\": course_name,\n",
    "            \"lecturer\": lecturer_obj[\"name\"],\n",
    "            \"grade\": grade,\n",
    "            \"style\": style,\n",
    "            \"aspects\": aspect_labels,\n",
    "            \"review_text\": ref_text,\n",
    "        }\n",
    "\n",
    "    def generate_many(self, n: int):\n",
    "        return [self.generate_single() for _ in range(n)]\n",
    "\n",
    "    @staticmethod\n",
    "    def save_jsonl(dataset, filename: str):\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            for item in dataset:\n",
    "                f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2cfc9e5-7514-4b70-a3c9-7e5e69705c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"course_name\": \"Linear Algebra\",\n",
      "    \"lecturer\": \"Dr. Adler\",\n",
      "    \"grade\": \"A (Excellent)\",\n",
      "    \"style\": \"Short (Max 10-15 words. Fragments allowed)\",\n",
      "    \"aspects\": {\n",
      "        \"difficulty\": \"negative\",\n",
      "        \"workload\": \"neutral\",\n",
      "        \"materials\": \"negative\"\n",
      "    },\n",
      "    \"review_text\": \"tough concept, bad slides & book\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # -------- choose model provider --------\n",
    "\n",
    "    # ----- OpenAI -----\n",
    "    # llm = LLMClient(\n",
    "    #     provider=\"openai\",\n",
    "    #     api_key=\"YOUR_OPENAI_KEY\",\n",
    "    #     model=\"gpt-4o-mini\"\n",
    "    # )\n",
    "\n",
    "    # ----- Ollama -----\n",
    "    llm = LLMClient(\n",
    "        provider=\"ollama\",\n",
    "        model=\"llama3\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    Robustgenerator = RobustDataGenerator(llm)\n",
    "\n",
    "    # Generate one example\n",
    "    Robustexample = Robustgenerator.generate_single()\n",
    "\n",
    "\n",
    "    print(json.dumps( Robustexample, indent=4, ensure_ascii=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bab79bb7-0566-4769-8eab-4fd68b230444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'course_name': 'Computer Networks',\n",
       "  'lecturer': 'Prof. Baruch',\n",
       "  'grade': 'D (Barely passed)',\n",
       "  'style': \"Analytic but Simple (Explains 'why' but uses simple language)\",\n",
       "  'aspects': {'workload': 'neutral'},\n",
       "  'review_text': 'fair workload,decent teaching'},\n",
       " {'course_name': 'Cyber Security Basics',\n",
       "  'lecturer': 'Prof. Klein',\n",
       "  'grade': 'B (Good)',\n",
       "  'style': 'Rant/Rave (Emotional, very subjective, lots of punctuation !!! or ...)',\n",
       "  'aspects': {'clarity': 'negative', 'support': 'positive'},\n",
       "  'review_text': \"In y opinion, i'm still trying 2 wrap my head around it... but his tias r literally lifesavers\"},\n",
       " {'course_name': 'Machine Learning',\n",
       "  'lecturer': 'Prof. Levi',\n",
       "  'grade': 'D (Barely passed)',\n",
       "  'style': \"Analytic but Simple (Explains 'why' but uses simple language)\",\n",
       "  'aspects': {'support': 'neutral',\n",
       "   'clarity': 'negative',\n",
       "   'lecturer_quality': 'neutral'},\n",
       "  'review_text': 'the support was okay but not super helpful. the material was confusing and i got lost'},\n",
       " {'course_name': 'Web Development',\n",
       "  'lecturer': 'Dr. Shapira',\n",
       "  'grade': 'F (Failed)',\n",
       "  'style': \"Analytic but Simple (Explains 'why' but uses simple language)\",\n",
       "  'aspects': {'exam_fairness': 'negative'},\n",
       "  'review_text': 'this exam was super unfair'},\n",
       " {'course_name': 'Operating Systems',\n",
       "  'lecturer': 'Prof. Klein',\n",
       "  'grade': 'C (Average)',\n",
       "  'style': \"Analytic but Simple (Explains 'why' but uses simple language)\",\n",
       "  'aspects': {'workload': 'positive', 'relevance': 'negative'},\n",
       "  'review_text': \"prof klein's lectures ar intense\"},\n",
       " {'course_name': 'Databases',\n",
       "  'lecturer': 'Prof. Levi',\n",
       "  'grade': 'D (Barely passed)',\n",
       "  'style': 'Simple & Direct (Use only common words. No academic jargon. Like talking to a friend)',\n",
       "  'aspects': {'materials': 'neutral', 'clarity': 'neutral'},\n",
       "  'review_text': 'the course is okay'},\n",
       " {'course_name': 'Calculus 2',\n",
       "  'lecturer': 'Prof. Klein',\n",
       "  'grade': 'D (Barely passed)',\n",
       "  'style': 'Short (Max 10-15 words. Fragments allowed)',\n",
       "  'aspects': {'workload': 'positive', 'support': 'neutral'},\n",
       "  'review_text': 'heav workload ruined weekends'},\n",
       " {'course_name': 'Introduction to Programming',\n",
       "  'lecturer': 'Dr. Adler',\n",
       "  'grade': 'D (Barely passed)',\n",
       "  'style': 'Simple & Direct (Use only common words. No academic jargon. Like talking to a friend)',\n",
       "  'aspects': {'interest': 'neutral',\n",
       "   'relevance': 'positive',\n",
       "   'lecturer_quality': 'neutral'},\n",
       "  'review_text': 'he explains stuff clearly'},\n",
       " {'course_name': 'Calculus 2',\n",
       "  'lecturer': 'Dr. Mizrahi',\n",
       "  'grade': 'D (Barely passed)',\n",
       "  'style': \"Analytic but Simple (Explains 'why' but uses simple language)\",\n",
       "  'aspects': {'lecturer_quality': 'neutral', 'clarity': 'neutral'},\n",
       "  'review_text': \"the lecturer was okay, didn't really connect with the way he taught. concepts were hard to grasp, especially series convergence tests - made it tough to get a good grade\"},\n",
       " {'course_name': 'Cyber Security Basics',\n",
       "  'lecturer': 'Prof. Klein',\n",
       "  'grade': 'D (Barely passed)',\n",
       "  'style': 'Rant/Rave (Emotional, very subjective, lots of punctuation !!! or ...)',\n",
       "  'aspects': {'overall_experience': 'negative', 'exam_fairness': 'neutral'},\n",
       "  'review_text': 'it was so boring and hard to learn tbh the whole semester was a struggle'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Robustdataset = Robustgenerator.generate_many(10)\n",
    "Robustdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e85d4-07c6-4a7c-8c9a-773e8c0bfe52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f81b4-818e-4a5b-bb7e-d16504f96a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fcabd3-6782-4b7f-bd0a-db368b54f229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bedf8527-80a4-45da-a0f2-3c36a8488204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ×”× ×—×”: ×”××—×œ×§×” RobustDataGenerator ×›×‘×¨ ××•×’×“×¨×ª ×œ××¢×œ×” ×‘×§×•×“ ×©×œ×š\n",
    "# ×•×”-llm_client ×©×œ×š ×›×‘×¨ ×××•×ª×—×œ\n",
    "\n",
    "def count_existing_reviews(filename):\n",
    "    \"\"\"×¤×•× ×§×¦×™×™×ª ×¢×–×¨ ×œ×¡×¤×™×¨×ª ×©×•×¨×•×ª ×‘×§×•×‘×¥ ×§×™×™×\"\"\"\n",
    "    if not os.path.exists(filename):\n",
    "        return 0\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "def generate_dataset_in_batches(generator, filename=\"reviews_dataset.jsonl\", target_total=5000, batch_size=100):\n",
    "    \"\"\"\n",
    "    ××™×™×¦×¨×ª ×“××˜×” ×‘× ×’×œ×•×ª ×•×©×•××¨×ª ×œ×§×•×‘×¥.\n",
    "    generator: ×”××•×¤×¢ ×©×œ ×”××—×œ×§×” RobustDataGenerator\n",
    "    filename: ×©× ×”×§×•×‘×¥ ×œ×©××™×¨×”\n",
    "    target_total: ×”×™×¢×“ ×”×¡×•×¤×™ ×©×œ ×‘×™×§×•×¨×•×ª\n",
    "    batch_size: ×›××” ×œ×™×™×¦×¨ ×‘×›×œ ×¡×™×‘×•×‘ (××•××œ×¥ 50-100)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ×‘×“×™×§×” ×›××” ×›×‘×¨ ×™×© ×œ× ×• (×›×“×™ ×œ× ×œ×“×¨×•×¡ ××• ×œ×™×™×¦×¨ ×¡×ª× ×× ×¢×¦×¨× ×• ×‘×××¦×¢)\n",
    "    current_count = count_existing_reviews(filename)\n",
    "    print(f\"ğŸ“‚ ×”×§×•×‘×¥ '{filename}' ××›×™×œ ×›×¨×’×¢ {current_count} ×‘×™×§×•×¨×•×ª.\")\n",
    "    \n",
    "    if current_count >= target_total:\n",
    "        print(\"âœ… ×”×™×¢×“ ×›×‘×¨ ×”×•×©×’! ××™×Ÿ ×¦×•×¨×š ×œ×™×™×¦×¨ ×¢×•×“.\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸš€ ××ª×—×™×œ ×™×™×¦×•×¨ ×©×œ ×¢×•×“ {target_total - current_count} ×‘×™×§×•×¨×•×ª...\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. ×”×œ×•×œ××” ×”×¨××©×™×ª\n",
    "    while current_count < target_total:\n",
    "        # ×—×™×©×•×‘ ×›××” × ×©××¨ ×›×“×™ ×œ× ×œ×—×¨×•×’ ×‘×‘××¥' ×”××—×¨×•×Ÿ\n",
    "        remaining = target_total - current_count\n",
    "        current_batch_size = min(batch_size, remaining)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # ×™×¦×™×¨×ª ×”×‘××¥'\n",
    "            print(f\"âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ {current_batch_size} ×‘×™×§×•×¨×•×ª... \", end=\"\", flush=True)\n",
    "            batch_data = generator.generate_many(current_batch_size)\n",
    "            \n",
    "            # ×©××™×¨×” ×œ×§×•×‘×¥ (××¦×‘ 'a' = append)\n",
    "            with open(filename, \"a\", encoding=\"utf-8\") as f:\n",
    "                for review in batch_data:\n",
    "                    f.write(json.dumps(review, ensure_ascii=False) + \"\\n\")\n",
    "            \n",
    "            # ×¢×“×›×•×Ÿ ××•× ×”\n",
    "            current_count += len(batch_data)\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            print(f\"âœ… ×‘×•×¦×¢ ({elapsed:.1f} ×©× ×™×•×ª).\")\n",
    "            print(f\"ğŸ“Š ×¡×”\\\"×› ×‘×“××˜×”-×¡×˜: {current_count} / {target_total}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ ×©×’×™××” ×‘×™×™×¦×•×¨ ×”×‘××¥': {e}\")\n",
    "            print(\"×××ª×™×Ÿ 5 ×©× ×™×•×ª ×•×× ×¡×” ×©×•×‘...\")\n",
    "            time.sleep(5)\n",
    "            # ×œ× ××¢×œ×™× ××ª ×”××•× ×”, ×”×œ×•×œ××” ×ª× ×¡×” ×©×•×‘\n",
    "            continue\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"ğŸ‰ ×¡×™×™×× ×•! ×”×§×•×‘×¥ '{filename}' ××›×™×œ ×›×¢×ª {current_count} ×‘×™×§×•×¨×•×ª.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "71da8110-6912-44cd-b17e-506225bf9319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ ×”×§×•×‘×¥ 'final_student_reviews.jsonl' ××›×™×œ ×›×¨×’×¢ 450 ×‘×™×§×•×¨×•×ª.\n",
      "ğŸš€ ××ª×—×™×œ ×™×™×¦×•×¨ ×©×œ ×¢×•×“ 4550 ×‘×™×§×•×¨×•×ª...\n",
      "--------------------------------------------------\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (278.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 500 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 550 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.8 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 600 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.2 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 650 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 700 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 750 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 800 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 850 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (280.9 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 900 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (280.2 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 950 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1000 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1050 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1100 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1150 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1200 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.4 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1250 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1300 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.2 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1350 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1400 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1450 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.4 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1500 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1550 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (279.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1600 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1650 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1700 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.8 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1750 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (288.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1800 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1850 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1900 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 1950 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.8 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2000 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.9 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2050 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2100 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (289.2 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2150 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2200 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2250 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.4 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2300 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (279.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2350 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2400 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (287.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2450 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (288.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2500 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2550 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (280.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2600 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2650 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2700 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.9 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2750 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2800 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.2 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2850 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2900 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 2950 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3000 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3050 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.2 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3100 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (288.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3150 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.4 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3200 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.8 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3250 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3300 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (278.8 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3350 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3400 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3450 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.9 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3500 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3550 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3600 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3650 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3700 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.9 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3750 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3800 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3850 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3900 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 3950 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4000 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4050 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4100 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4150 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (287.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4200 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.8 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4250 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4300 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.7 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4350 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (287.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4400 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.9 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4450 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4500 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.6 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4550 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (288.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4600 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (282.1 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4650 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (281.8 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4700 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (286.0 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4750 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (285.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4800 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (289.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4850 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.3 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4900 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (283.5 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 4950 / 5000\n",
      "âš™ï¸  ××™×™×¦×¨ ×‘××¥' ×©×œ 50 ×‘×™×§×•×¨×•×ª... âœ… ×‘×•×¦×¢ (284.2 ×©× ×™×•×ª).\n",
      "ğŸ“Š ×¡×”\"×› ×‘×“××˜×”-×¡×˜: 5000 / 5000\n",
      "--------------------------------------------------\n",
      "ğŸ‰ ×¡×™×™×× ×•! ×”×§×•×‘×¥ 'final_student_reviews.jsonl' ××›×™×œ ×›×¢×ª 5000 ×‘×™×§×•×¨×•×ª.\n"
     ]
    }
   ],
   "source": [
    "# --- ×“×•×’××” ×œ×©×™××•×© ---\n",
    "\n",
    "llm = LLMClient(\n",
    "    provider=\"ollama\",\n",
    "    model=\"llama3\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "# 1. ××ª×—×•×œ ×”×’× ×¨×˜×•×¨ (×”×—×œ×£ ××ª llm_client ×‘×œ×§×•×— ×”×××™×ª×™ ×©×œ×š)\n",
    "my_generator = RobustDataGenerator(llm_client=llm)\n",
    "\n",
    "# 2. ×”×¨×¦×ª ×”×¤×•× ×§×¦×™×”\n",
    "generate_dataset_in_batches(\n",
    "    generator=my_generator, \n",
    "    filename=\"final_student_reviews.jsonl\", \n",
    "    target_total=5000, \n",
    "    batch_size=50  # ××¤×©×¨ ×œ×”×•×¨×™×“ ×œ-50 ×× ×™×© timeouts\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543d8d8-45d1-4ee7-ace2-74e39d4692a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
