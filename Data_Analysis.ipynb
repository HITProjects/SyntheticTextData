{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65c661dd-6a35-4f10-a041-a776378a495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Successfully loaded file: synthetic_logs_20251120_230757.csv ---\n",
      "\n",
      "--- First 5 Rows of Generated Data ---\n",
      "               timesamp source_ip http_method  \\\n",
      "0  2021-07-16T13:57:49Z   1.2.3.4         GET   \n",
      "1  2021-07-16T13:57:49Z   1.2.3.4         GET   \n",
      "2  2021-07-16T13:57:49Z   1.2.3.4         GET   \n",
      "3  2021-07-16T13:57:49Z   1.2.3.4         GET   \n",
      "4  2021-07-16T13:57:49Z   1.2.3.4         GET   \n",
      "\n",
      "                                       requested_url           query_params  \\\n",
      "0                               /api/v1/product/list  &sortby=id,name,price   \n",
      "1          /api/v1/product/list?sortby=id,name,price                    NaN   \n",
      "2          /api/v1/product/list?sortby=id,name,price                    NaN   \n",
      "3          /api/v1/product/list?sortby=id,name,price                    NaN   \n",
      "4  /api/v1/product/list?sortby=id,name,price&is_m...                    NaN   \n",
      "\n",
      "  is_malicious  \n",
      "0          NaN  \n",
      "1         True  \n",
      "2         True  \n",
      "3         True  \n",
      "4         True  \n",
      "\n",
      "--- DataFrame Info (Check for NaN) ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6 entries, 0 to 5\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   timesamp       6 non-null      object\n",
      " 1   source_ip      6 non-null      object\n",
      " 2   http_method    6 non-null      object\n",
      " 3   requested_url  6 non-null      object\n",
      " 4   query_params   1 non-null      object\n",
      " 5   is_malicious   5 non-null      object\n",
      "dtypes: object(6)\n",
      "memory usage: 420.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1. מציאת הקובץ האחרון שנוצר \n",
    "# נחפש את כל הקבצים המתחילים ב-'synthetic_logs_' בתיקייה הנוכחית\n",
    "list_of_files = glob.glob('synthetic_logs_*.csv') \n",
    "# נבחר את הקובץ שנוצר אחרון\n",
    "latest_file = max(list_of_files, key=os.path.getctime)\n",
    "\n",
    "# 2. טעינת הקובץ ל-DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(latest_file)\n",
    "    print(f\"\\n--- Successfully loaded file: {latest_file} ---\")\n",
    "    \n",
    "    # 3. הצגת חמש השורות הראשונות\n",
    "    print(\"\\n--- First 5 Rows of Generated Data ---\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # 4. הצגת מידע על הנתונים (כדי לראות ערכי NaN)\n",
    "    print(\"\\n--- DataFrame Info (Check for NaN) ---\")\n",
    "    df.info()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c750c7fb-0fa2-4cb3-b6e9-6ff814a9a9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 1. Fixing Column Typos ---\n",
      "Columns renamed successfully.\n",
      "\n",
      "--- Data Cleaning Summary ---\n",
      "Total non-malicious (False): 1\n",
      "Total malicious (True): 5\n",
      "Missing values after cleanup: 0\n",
      "\n",
      "Data is ready for Model Training (Benchmark)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itaym\\AppData\\Local\\Temp\\ipykernel_27852\\1174559681.py:16: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['is_malicious'] = df['is_malicious'].fillna(False).astype(bool)\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is the DataFrame loaded in the previous step\n",
    "\n",
    "# --- 1. תיקון שמות העמודות (Fixing Typos) ---\n",
    "print(\"\\n--- 1. Fixing Column Typos ---\")\n",
    "df.rename(columns={'timesamp': 'timestamp', \n",
    "                   # ניתן להוסיף כאן תיקונים נוספים אם תתגלה טעות בעתיד\n",
    "                  }, inplace=True)\n",
    "print(\"Columns renamed successfully.\")\n",
    "\n",
    "\n",
    "# --- 2. טיפול בערכי NaN ובערכים חסרים ---\n",
    "\n",
    "# א. טיפול בערכי התווית (is_malicious): \n",
    "# נמלא את הערך החסר (NaN) ב-False, ונמיר את העמודה לטיפוס בוליאני.\n",
    "# הערך True מופיע כטקסט, לכן נשתמש בהמרה ל-boolean.\n",
    "df['is_malicious'] = df['is_malicious'].fillna(False).astype(bool)\n",
    "\n",
    "# ב. טיפול בערכים החסרים בפרמטרים (query_params): \n",
    "# נמלא NaN במחרוזת ריקה כדי למנוע קריסה בהמשך ניתוח הטקסט.\n",
    "df['query_params'] = df['query_params'].fillna(\"\")\n",
    "\n",
    "\n",
    "# --- 3. הכנת הנתונים למודל (Feature & Target) ---\n",
    "\n",
    "# בחירת המאפיין (הטקסט) ומשתנה המטרה (התווית)\n",
    "X = df['query_params']\n",
    "y = df['is_malicious']\n",
    "\n",
    "print(\"\\n--- Data Cleaning Summary ---\")\n",
    "print(f\"Total non-malicious (False): {y.value_counts().get(False, 0)}\")\n",
    "print(f\"Total malicious (True): {y.value_counts().get(True, 0)}\")\n",
    "print(f\"Missing values after cleanup: {df.isnull().sum().sum()}\")\n",
    "\n",
    "print(\"\\nData is ready for Model Training (Benchmark)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed2fdeb-2709-49c3-b9d9-8ea18df9a2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Benchmark Training (Logistic Regression) ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     18\u001b[0m X_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# --- 3. חלוקה ל-Train/Test ---\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# נשתמש ב-stratify כדי לוודא שחלוקת המחלקות הלא מאוזנת נשמרת.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# הערה: עקב גודל הנתונים הקטן (6 רשומות), ה-Test set יהיה קטן מאוד.\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\n\u001b[0;32m     25\u001b[0m     X_vectorized, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# --- 4. אימון המודל ---\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2872\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2868\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2870\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2872\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2874\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2877\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2878\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2879\u001b[0m     )\n\u001b[0;32m   2880\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:1909\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1879\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1880\u001b[0m \n\u001b[0;32m   1881\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1907\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1908\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1909\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1910\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2318\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   2316\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   2317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 2318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2322\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2323\u001b[0m     )\n\u001b[0;32m   2325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   2326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   2329\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# --- 1. הכנת נתונים (Target והמאפיין הטקסטואלי) ---\n",
    "\n",
    "# X: המאפיין הטקסטואלי (הפרמטרים של הלוג)\n",
    "X = df['query_params']\n",
    "# y: משתנה המטרה (התווית - True/False)\n",
    "y = df['is_malicious']\n",
    "\n",
    "print(\"\\n--- Starting Benchmark Training (Logistic Regression) ---\")\n",
    "\n",
    "# --- 2. וקטוריזציה של הטקסט (הפיכת טקסט למספרים) ---\n",
    "# CountVectorizer היא השיטה הפשוטה ביותר ל-Benchmark\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# --- 3. חלוקה ל-Train/Test ---\n",
    "# נשתמש ב-stratify כדי לוודא שחלוקת המחלקות הלא מאוזנת נשמרת.\n",
    "# הערה: עקב גודל הנתונים הקטן (6 רשומות), ה-Test set יהיה קטן מאוד.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vectorized, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# --- 4. אימון המודל ---\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# --- 5. הערכה (Evaluation) ---\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Evaluation Results ---\")\n",
    "\n",
    "# מטריצת בלבול (Confusion Matrix)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# F1-Score (מדד קריטי לנתונים לא מאוזנים)\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='binary'):.4f}\")\n",
    "\n",
    "# Accuracy (דיוק כללי)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "print(\"\\nBenchmark Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb784e9a-afbc-4108-b844-2a4b7159033d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting K-Fold Cross-Validation Benchmark ---\n",
      "Running 3-Fold Cross-Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\itaym\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.True_",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# אימון המודל\u001b[39;00m\n\u001b[0;32m     40\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# חיזוי והערכה\u001b[39;00m\n\u001b[0;32m     44\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1276\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1271\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1272\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m > 1 does not have any effect when\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1273\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msolver\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1274\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m = \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs))\n\u001b[0;32m   1275\u001b[0m         )\n\u001b[1;32m-> 1276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m _fit_liblinear(\n\u001b[0;32m   1277\u001b[0m         X,\n\u001b[0;32m   1278\u001b[0m         y,\n\u001b[0;32m   1279\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mC,\n\u001b[0;32m   1280\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept,\n\u001b[0;32m   1281\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_scaling,\n\u001b[0;32m   1282\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m   1283\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty,\n\u001b[0;32m   1284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual,\n\u001b[0;32m   1285\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter,\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m   1289\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1290\u001b[0m     )\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1187\u001b[0m, in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m   1185\u001b[0m     classes_ \u001b[38;5;241m=\u001b[39m enc\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes_) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1188\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1189\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1190\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1191\u001b[0m         )\n\u001b[0;32m   1193\u001b[0m     class_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(class_weight, classes\u001b[38;5;241m=\u001b[39mclasses_, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m   1194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: np.True_"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# X, y הם הנתונים שנוקו בשלב הקודם\n",
    "X = df['query_params']\n",
    "y = df['is_malicious']\n",
    "\n",
    "print(\"\\n--- Starting K-Fold Cross-Validation Benchmark ---\")\n",
    "\n",
    "# --- 1. וקטוריזציה של הטקסט (על כל הנתונים) ---\n",
    "vectorizer = CountVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# --- 2. הגדרת Cross-Validation (שימוש ב-StratifiedKFold בגלל האיזון) ---\n",
    "# נבחר K=3 קיפולים (הערה: זה המקסימום ההגיוני עם 6 רשומות)\n",
    "# StratifiedKFold משמר את יחס המחלקות בכל קיפול (K-Fold)\n",
    "N_SPLITS = 3\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "# מערכים לאחסון תוצאות\n",
    "f1_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "\n",
    "# --- 3. אימון והערכה איטרטיבית ---\n",
    "print(f\"Running {N_SPLITS}-Fold Cross-Validation...\")\n",
    "i = 0\n",
    "for train_index, test_index in skf.split(X_vectorized, y):\n",
    "    i += 1\n",
    "    \n",
    "    # חלוקה ל-Train/Test עבור הקיפול הנוכחי\n",
    "    X_train, X_test = X_vectorized[train_index], X_vectorized[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # אימון המודל\n",
    "    model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # חיזוי והערכה\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # שמירת המדדים\n",
    "    f1 = f1_score(y_test, y_pred, average='binary', zero_division=0)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    f1_scores.append(f1)\n",
    "    accuracy_scores.append(acc)\n",
    "    print(f\"Fold {i} Results: Accuracy={acc:.2f}, F1-Score={f1:.2f}\")\n",
    "\n",
    "\n",
    "# --- 4. סיכום התוצאות ---\n",
    "print(\"\\n--- Final Benchmark Results (Macro Average) ---\")\n",
    "print(f\"Average F1 Score (across {N_SPLITS} folds): {np.mean(f1_scores):.4f}\")\n",
    "print(f\"Average Accuracy (across {N_SPLITS} folds): {np.mean(accuracy_scores):.4f}\")\n",
    "\n",
    "print(\"\\nBenchmark Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33f6d488-772e-40ad-b1f9-214c37c010b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Final Benchmark with Simple Train/Test Split ---\n",
      "Training samples: 5, Test samples: 1\n",
      "FATAL ERROR: Could not train model. The small split size still resulted in only one class in the training set.\n",
      "This confirms the synthetic dataset is TOO SMALL to run a valid benchmark.\n",
      "\n",
      "Benchmark Attempt Done.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # שימוש ב-TFIDF במקום CountVectorizer (עדיף)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# X, y הם הנתונים שנוקו בשלב הקודם\n",
    "X = df['query_params']\n",
    "y = df['is_malicious']\n",
    "\n",
    "print(\"\\n--- Starting Final Benchmark with Simple Train/Test Split ---\")\n",
    "\n",
    "# --- 1. וקטוריזציה של הטקסט (TFIDF) ---\n",
    "# נשתמש ב-TFIDF, שהוא חזק יותר בטיפול במונחים חשובים\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "\n",
    "# --- 2. חלוקה ל-Train/Test (ללא Stratify) ---\n",
    "# עקב הכשל ב-stratify, נשתמש בחלוקה פשוטה, תוך סיכון לאי-ייצוג.\n",
    "# נשתמש ב-Test Size קטן מאוד כדי להשאיר דוגמאות False ב-Train.\n",
    "# בגלל 1 דוגמה False, נחלק 5/1.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vectorized, y, test_size=0.15, random_state=42\n",
    ")\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# --- 3. אימון המודל ---\n",
    "model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "# במידה ו-y_train מכיל רק True, זה עדיין יכשל. \n",
    "# נכריח את המערכת לרוץ על הנתונים הזמינים.\n",
    "try:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # --- 4. הערכה (Evaluation) ---\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(\"\\n--- Evaluation Results ---\")\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred, average='binary', zero_division=0):.4f}\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"FATAL ERROR: Could not train model. The small split size still resulted in only one class in the training set.\")\n",
    "    print(\"This confirms the synthetic dataset is TOO SMALL to run a valid benchmark.\")\n",
    "    \n",
    "print(\"\\nBenchmark Attempt Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94e309-a7b8-4a05-81b1-098b8f63fe73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
